{
 "metadata": {
  "name": "",
  "signature": "sha256:a0e62d294ea7285f53607171febe69d7747073ff63376039a44190ec561c1c3e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import nltk\n",
      "nltk.data.path.append('/Users/cem/Documents/_code/nltk')\n",
      "from nltk.book import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "*** Introductory Examples for the NLTK Book ***\n",
        "Loading text1, ..., text9 and sent1, ..., sent9\n",
        "Type the name of the text or sentence to view it.\n",
        "Type: 'texts()' or 'sents()' to list the materials.\n",
        "text1:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Moby Dick by Herman Melville 1851\n",
        "text2:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Sense and Sensibility by Jane Austen 1811\n",
        "text3:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " The Book of Genesis\n",
        "text4:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Inaugural Address Corpus\n",
        "text5:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Chat Corpus\n",
        "text6:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Monty Python and the Holy Grail\n",
        "text7:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Wall Street Journal\n",
        "text8: Personals Corpus\n",
        "text9:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " The Man Who Was Thursday by G . K . Chesterton 1908\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "nltk has a big library of corpora for experimentation and analysis.\n",
      "Gutenberg, Brown, web text, chat text, and chatbots (nltk.chat.chatbot)\n",
      "\n",
      "There is also a corpus of instant messaging chat sessions, originally collected by the Naval Postgraduate School for research on automatic detection of Internet predators. The corpus contains over 10,000 posts, anonymized by replacing usernames with generic names of the form UserNNN, and manually edited to remove any other identifying information. The corpus is organized into 15 files, where each file contains several hundred posts collected on a given date, for an age-specific chatroom (teens, 20s, 30s, 40s, plus a generic adults chatroom). The filename contains the date, chat- room, and number of posts; e.g., 10-19-20s_706posts.xml contains 706 posts gathered from the 20s chat room on 10/19/2006."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chatroom = nltk.corpus.nps_chat.posts('10-19-20s_706posts.xml')\n",
      "print ' '.join(chatroom[123])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "i do n't want hot pics of a female , I can look in a mirror .\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.corpus.genesis.sents('lolcat.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[u'Oh', u'hai', u'.'], [u'In', u'teh', u'beginnin', u'Ceiling', u'Cat', u'maded', u'teh', u'skiez', u'An', u'da', u'Urfs', u',', u'but', u'he', u'did', u'not', u'eated', u'dem', u'.'], ...]\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import verbnet as vn\n",
      "print vn.lemmas()[-20:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'yak', u'yammer', u'yank', u'yap', u'yawn', u'yearn', u'yell', u'yellow', u'yelp', u'yield', u'yip', u'yodel', u'yoke', u'yowl', u'zest', u'zigzag', u'zing', u'zip', u'zipcode', u'zoom']\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# word meaning trees\n",
      "from nltk.corpus import wordnet as wn\n",
      "# wn html browser\n",
      "#nltk.app.wordnet()\n",
      "\n",
      "wn.synsets('help')[6].lemma_names()\n",
      "\n",
      "sex = wn.synset('sex.n.01')\n",
      "print sex.definition()\n",
      "sex.hyponyms()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "activities associated with sexual intercourse\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[Synset('autoeroticism.n.01'),\n",
        " Synset('bestiality.n.02'),\n",
        " Synset('bisexuality.n.02'),\n",
        " Synset('bondage.n.03'),\n",
        " Synset('carnal_abuse.n.01'),\n",
        " Synset('conception.n.02'),\n",
        " Synset('coupling.n.03'),\n",
        " Synset('foreplay.n.01'),\n",
        " Synset('heterosexuality.n.01'),\n",
        " Synset('homosexuality.n.01'),\n",
        " Synset('lechery.n.01'),\n",
        " Synset('outercourse.n.01'),\n",
        " Synset('perversion.n.02'),\n",
        " Synset('pleasure.n.05'),\n",
        " Synset('promiscuity.n.01'),\n",
        " Synset('reproduction.n.05'),\n",
        " Synset('safe_sex.n.01'),\n",
        " Synset('sexual_intercourse.n.01'),\n",
        " Synset('sexual_love.n.02')]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def synset(word,type='n',num='01'): return wn.synset(word+'.'+type+'.'+num)\n",
      "\n",
      "print synset('lost','a','01').definition()\n",
      "print synset('lost','a','02').definition()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no longer in your possession or control; unable to be found or recovered\n",
        "having lost your bearings; confused as to time or place or personal identity\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ocean = synset('ocean')\n",
      "sea = synset('sea')\n",
      "\n",
      "see = synset('see',type='v',num='01')\n",
      "\n",
      "print sea.definition()\n",
      "print see.definition()\n",
      "print\n",
      "print sea.lowest_common_hypernyms(ocean)\n",
      "print sea.path_similarity(ocean)\n",
      "sea.path_similarity?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "a division of an ocean or a large body of salt water partially enclosed by land\n",
        "perceive by sight or have the power to perceive by sight\n",
        "\n",
        "[Synset('body_of_water.n.01')]\n",
        "0.333333333333\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pprint import pprint\n",
      "\n",
      "hyper = lambda s:s.hypernyms()\n",
      "\n",
      "feeling = synset('feeling')\n",
      "sick = synset('sick','a')\n",
      "\n",
      "pprint(feeling.tree(hyper))\n",
      "print \n",
      "pprint(sick.tree(hyper))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Synset('feeling.n.01'),\n",
        " [Synset('state.n.02'),\n",
        "  [Synset('attribute.n.02'),\n",
        "   [Synset('abstraction.n.06'), [Synset('entity.n.01')]]]]]\n",
        "\n",
        "[Synset('ill.a.01')]\n",
        "[Synset('ill.a.01')]\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Now that we can do a part of speech tag, the next step is do some chunking. Noun phrase chunking.\n",
      "(We) saw (the yellow dog). (2 NP chunks, parenthesis)\n",
      "(The market) for (system-management software) for (Digital's hardware) is fragmented enough that (a giant) such as (Computer Associates) should do well there. (5 NP chunks)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#another important part of NLP is sentencing tagging. \n",
      "mytext = nltk.word_tokenize('My name is Crazy Fish')\n",
      "nltk.pos_tag(mytext)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "[('My', 'PRP$'),\n",
        " ('name', 'NN'),\n",
        " ('is', 'VBZ'),\n",
        " ('Crazy', 'NNP'),\n",
        " ('Fish', 'NNP')]"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Alphabetical list of part-of-speech tags used in the Penn Treebank Project:\n",
      "\n",
      "CC Coordinating conjunction\n",
      "CD Cardinal number\n",
      "DT Determiner\n",
      "EX Existential there\n",
      "FW Foreign word\n",
      "IN Preposition or subordinating conjunction\n",
      "JJ Adjective\n",
      "JJR Adjective, comparative\n",
      "JJS Adjective, superlative\n",
      "LS List item marker\n",
      "MD Modal\n",
      "NN Noun, singular or mass\n",
      "NNS Noun, plural\n",
      "NNP Proper noun, singular\n",
      "NNPS Proper noun, plural\n",
      "PDT Predeterminer\n",
      "POS Possessive ending\n",
      "PRP Personal pronoun\n",
      "PRP$ Possessive pronoun\n",
      "RB Adverb\n",
      "RBR Adverb, comparative\n",
      "RBS Adverb, superlative\n",
      "RP Particle\n",
      "SYM Symbol\n",
      "TO to\n",
      "UH Interjection\n",
      "VB Verb, base form\n",
      "VBD Verb, past tense\n",
      "VBG Verb, gerund or present participle\n",
      "VBN Verb, past participle\n",
      "VBP Verb, non-3rd person singular present\n",
      "VBZ Verb, 3rd person singular present\n",
      "WDT Wh-determiner\n",
      "WP Wh-pronoun\n",
      "WP$ Possessive wh-pronoun\n",
      "WRB Wh-adverb\n",
      "\n",
      "http://www.cis.upenn.edu/~treebank/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize('San Francisco is always rainy')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/cem/Documents/_code/anaconda/lib/python2.7/site-packages/IPython/core/formatters.py:239: FormatterWarning: Exception in image/png formatter: \n",
        "\n",
        "===========================================================================\n",
        "NLTK was unable to find the gs file!\n",
        "Use software specific configuration paramaters or set the PATH environment variable.\n",
        "===========================================================================\n",
        "  FormatterWarning,\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "Tree('S', [Tree('GPE', [('San', 'NNP')]), Tree('PERSON', [('Francisco', 'NNP')]), ('is', 'VBZ'), ('always', 'RB'), ('rainy', 'JJ')])"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We can chunk using regex parser by defining a grammar.\n",
      "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"), (\"dog\", \"NN\"), (\"barked\", \n",
      "\"VBD\"), (\"at\", \"IN\"), (\"the\", \"DT\"), (\"cat\", \"NN\")] # a simple sentence with POS tags\n",
      "pattern = \"NP: {<DT>?<JJ>*<NN>}\" # define a tag pattern of an NP chunk\n",
      "NPChunker = nltk.RegexpParser(pattern) # create a chunk parser \n",
      "result = NPChunker . parse(sentence) # parse the example sentence\n",
      "print result "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(S\n",
        "  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
        "  barked/VBD\n",
        "  at/IN\n",
        "  (NP the/DT cat/NN))\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Walking to the taffrail, I was in time to make out, on the very edge of a darkness thrown by a towering black mass like the very gateway of Erebus\u2014yes, I was in time to catch an evanescent glimpse of my white hat left behind to mark the spot where the secret sharer of my cabin and of my thoughts, as though he were my second self, had lowered himself into the water to take his punishment: a free man, a proud swimmer striking out for a new destiny. \n",
      "\n",
      "\n",
      "(ROOT\n",
      "  (S\n",
      "    (S\n",
      "      (S\n",
      "        (VP (VBG Walking)\n",
      "          (PP (TO to)\n",
      "            (NP (DT the) (NN taffrail)))))\n",
      "      (, ,)\n",
      "      (NP (PRP I))\n",
      "      (VP (VBD was)\n",
      "        (PP (IN in)\n",
      "          (NP (NN time)))\n",
      "        (S\n",
      "          (VP (TO to)\n",
      "            (VP (VB make)\n",
      "              (PRT (RP out))\n",
      "              (, ,)\n",
      "              (PP (IN on)\n",
      "                (NP\n",
      "                  (NP (DT the) (JJ very) (NN edge))\n",
      "                  (PP (IN of)\n",
      "                    (NP\n",
      "                      (NP (DT a) (NNS darkness))\n",
      "                      (VP (VBN thrown)\n",
      "                        (PP (IN by)\n",
      "                          (NP\n",
      "                            (NP (DT a) (JJ towering) (JJ black) (NN mass))\n",
      "                            (PP (IN like)\n",
      "                              (NP\n",
      "                                (NP (DT the) (JJ very) (NN gateway))\n",
      "                                (PP (IN of)\n",
      "                                  (NP (NNP Erebus)))))))))))))))))\n",
      "    (: --)\n",
      "    (S\n",
      "      (INTJ (UH yes))\n",
      "      (, ,)\n",
      "      (NP (PRP I))\n",
      "      (VP (VBD was)\n",
      "        (PP (IN in)\n",
      "          (NP (NN time)))\n",
      "        (S\n",
      "          (VP (TO to)\n",
      "            (VP (VB catch)\n",
      "              (NP\n",
      "                (NP (DT an) (JJ evanescent) (NN glimpse))\n",
      "                (PP (IN of)\n",
      "                  (NP\n",
      "                    (NP (PRP$ my) (JJ white) (NN hat))\n",
      "                    (VP (VBN left)\n",
      "                      (PRT (RP behind))\n",
      "                      (S\n",
      "                        (VP (TO to)\n",
      "                          (VP (VB mark)\n",
      "                            (NP\n",
      "                              (NP\n",
      "                                (NP (DT the) (NN spot))\n",
      "                                (SBAR\n",
      "                                  (WHADVP (WRB where))\n",
      "                                  (S\n",
      "                                    (NP\n",
      "                                      (NP (DT the) (JJ secret) (NN sharer))\n",
      "                                      (PP\n",
      "                                        (PP (IN of)\n",
      "                                          (NP (PRP$ my) (NN cabin)))\n",
      "                                        (CC and)\n",
      "                                        (PP (IN of)\n",
      "                                          (NP (PRP$ my) (NNS thoughts)))))\n",
      "                                    (, ,)\n",
      "                                    (SBAR (RB as) (IN though)\n",
      "                                      (S\n",
      "                                        (NP (PRP he))\n",
      "                                        (VP (VBD were)\n",
      "                                          (NP (PRP$ my) (JJ second) (NN self)))))\n",
      "                                    (, ,)\n",
      "                                    (VP (VBD had)\n",
      "                                      (VP (VBN lowered)\n",
      "                                        (NP (PRP himself))\n",
      "                                        (PP (IN into)\n",
      "                                          (NP (DT the) (NN water)\n",
      "                                            (S\n",
      "                                              (VP (TO to)\n",
      "                                                (VP (VB take)\n",
      "                                                  (NP (PRP$ his) (NN punishment))))))))))))\n",
      "                              (: :)\n",
      "                              (NP\n",
      "                                (NP (DT a) (JJ free) (NN man))\n",
      "                                (, ,)\n",
      "                                (NP\n",
      "                                  (NP (DT a) (JJ proud) (NN swimmer))\n",
      "                                  (VP (VBG striking)\n",
      "                                    (PRT (RP out))\n",
      "                                    (PP (IN for)\n",
      "                                      (NP (DT a) (JJ new) (NN destiny)))))))))))))))))))\n",
      "    (. .)))\n",
      " "
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "This period of blue nights does not occur in subtropical California, where I lived for much of the time I will describe here and where the end of daylight is fast and lost in the blaze of the dropping sun, but it does occur in New York, where I live now.\n",
      "\n",
      "(ROOT\n",
      "  (S\n",
      "    (S\n",
      "      (NP\n",
      "        (NP (DT This) (NN period))\n",
      "        (PP (IN of)\n",
      "          (NP (JJ blue) (NNS nights))))\n",
      "      (VP (VBZ does) (RB not)\n",
      "        (VP (VB occur)\n",
      "          (PP (IN in)\n",
      "            (NP\n",
      "              (NP (NNP subtropical) (NNP California))\n",
      "              (, ,)\n",
      "              (SBAR\n",
      "                (WHADVP (WRB where))\n",
      "                (S\n",
      "                  (NP (PRP I))\n",
      "                  (VP (VBD lived)\n",
      "                    (PP (IN for)\n",
      "                      (NP\n",
      "                        (NP (RB much))\n",
      "                        (PP (IN of)\n",
      "                          (NP (DT the) (NN time)))))\n",
      "                    (SBAR\n",
      "                      (SBAR\n",
      "                        (S\n",
      "                          (NP (PRP I))\n",
      "                          (VP (MD will)\n",
      "                            (VP (VB describe)\n",
      "                              (ADVP (RB here))))))\n",
      "                      (CC and)\n",
      "                      (SBAR\n",
      "                        (WHADVP (WRB where))\n",
      "                        (S\n",
      "                          (NP\n",
      "                            (NP (DT the) (NN end))\n",
      "                            (PP (IN of)\n",
      "                              (NP (NN daylight))))\n",
      "                          (VP (VBZ is)\n",
      "                            (UCP\n",
      "                              (ADJP (JJ fast))\n",
      "                              (CC and)\n",
      "                              (VP (VBN lost)\n",
      "                                (PP (IN in)\n",
      "                                  (NP\n",
      "                                    (NP (DT the) (NN blaze))\n",
      "                                    (PP (IN of)\n",
      "                                      (NP (DT the) (VBG dropping) (NN sun)))))))))))))))))))\n",
      "    (, ,)\n",
      "    (CC but)\n",
      "    (S\n",
      "      (NP (PRP it))\n",
      "      (VP (VBZ does)\n",
      "        (VP (VB occur)\n",
      "          (PP (IN in)\n",
      "            (NP\n",
      "              (NP (NNP New) (NNP York))\n",
      "              (, ,)\n",
      "              (SBAR\n",
      "                (WHADVP (WRB where))\n",
      "                (S\n",
      "                  (NP (PRP I))\n",
      "                  (VP (VBP live)\n",
      "                    (ADVP (RB now))))))))))\n",
      "    (. .)))\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import treebank\n",
      "t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
      "t.draw()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Now lets drill down a bit more into the words themselves."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dict = nltk.corpus.cmudict.entries()\n",
      "pdict = nltk.corpus.cmudict.dict()\n",
      "\n",
      "# get arpabet spelling\n",
      "parsed = ['cambodian', 'road']\n",
      "print [ph for w in parsed for ph in pdict[w][0]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'K', u'AE2', u'M', u'B', u'OW1', u'D', u'IY0', u'AH0', u'N', u'R', u'OW1', u'D']\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sonorants = {\n",
      "'upper_fronts' : ['EY','AY','OY','IY'] ,\\\n",
      "'mid_fronts' : ['IH','EH','ER','AE'] ,\\\n",
      "'mids' : ['AX','AH','UH','AA'] ,\\\n",
      "'upper_backs' : ['OY','OW','UW','UH'] ,\\\n",
      "'mid_backs' : ['UH','AO','OY','AW'] ,\\\n",
      "'bottoms' : ['AE','AA','AO','AW'] ,\\\n",
      "}\n",
      "\n",
      "\n",
      "def match(phon1, phon2, sonorities=sonorants):\n",
      "  phon1 = re.sub(r'\\d','', phon1)  #strip off stresses\n",
      "  phon2 = re.sub(r'\\d','', phon2) \n",
      "  out = False\n",
      "  if phon1 == phon2: out = True\n",
      "  for key in sonorities.keys():\n",
      "    if (phon1 in sonorities[key] and phon2 in sonorities[key]):  out = True\n",
      "  return out    \n",
      "   \n",
      "match('AA','AO')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rhyme(pron1, pron2, start=0, length=1):\n",
      "  matches = []\n",
      "  for i in range(start,length):\n",
      "    matches.append(int(match(pron1[i],pron2[i])))\n",
      "  print matches\n",
      "  return sum(matches)\n",
      "\n",
      "t = [ph for ph in pdict['towed'][0]]\n",
      "s = [ph for ph in pdict['rowed'][0]]\n",
      "\n",
      "print t,s\n",
      "rhyme(t,r,0,3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'T', u'OW1', u'D'] [u'R', u'OW1', u'D']\n",
        "[0, 1, 1]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_rhyme(pattern, corpus=dict):\n",
      "  candidates = [(pron[0]+'-'+pron[-1], word) for (word, pron) in corpus if pron[-len(pattern):] == pattern]\n",
      "  cfd = nltk.ConditionalFreqDist(candidates)\n",
      "  for template in cfd.conditions():\n",
      "    print cfd[template].keys()\n",
      "  return\n",
      "\n",
      "find_rhyme(t)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'plateaued']\n",
        "[u'stowed']\n",
        "[u'toad', u'towed', u'toed']\n",
        "[u'bestowed']\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#basic stressed syllable pattern lookup\n",
      "\n",
      "def stress(pron):\n",
      "  s = [int(char) for phone in pron for char in phone if char.isdigit()]\n",
      "  for i in s:\n",
      "    if i==2:\n",
      "      i = 1   #remove secondary stresses\n",
      "  return s\n",
      "\n",
      "def match_word(foot,corpus=dict):\n",
      "  return [w for w, pron in corpus if stress(pron) == foot]\n",
      "\n",
      "match_word([0,0,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "[u'abidjan',\n",
        " u'abimael',\n",
        " u'abimaels',\n",
        " u'adoree',\n",
        " u'adorees',\n",
        " u'adrienne',\n",
        " u'aguillon',\n",
        " u'aleron',\n",
        " u'alleyoop',\n",
        " u'almaguer',\n",
        " u'almanzar',\n",
        " u'almazan',\n",
        " u'almelund',\n",
        " u'amadon',\n",
        " u'amaral',\n",
        " u'andujar',\n",
        " u'appointee',\n",
        " u'appointees',\n",
        " u'aquilar',\n",
        " u'armentor',\n",
        " u'arreguin',\n",
        " u'augustin',\n",
        " u'avelar',\n",
        " u'avenall',\n",
        " u'avenel',\n",
        " u'avenell',\n",
        " u'averell',\n",
        " u'averill',\n",
        " u'balaban',\n",
        " u'baldemar',\n",
        " u'baltazar',\n",
        " u'balthazor',\n",
        " u'banderas',\n",
        " u'becerril',\n",
        " u'bensenyore',\n",
        " u'bernadette',\n",
        " u'bernadine',\n",
        " u'bordenave',\n",
        " u'cadogan',\n",
        " u'carbajal',\n",
        " u'carreon',\n",
        " u'carvajal',\n",
        " u'casebeer',\n",
        " u'chandelier',\n",
        " u'chelyabinsk',\n",
        " u'christiane',\n",
        " u'christianne',\n",
        " u'comandeer',\n",
        " u'comandeered',\n",
        " u'comandeers',\n",
        " u'couvillion',\n",
        " u'couvillon',\n",
        " u'coval',\n",
        " u'dameron',\n",
        " u'dauphinee',\n",
        " u'davignon',\n",
        " u'deguzman',\n",
        " u'delamar',\n",
        " u'delosreyes',\n",
        " u'demaree',\n",
        " u'desecrate',\n",
        " u'desecrate',\n",
        " u'desecrates',\n",
        " u'desecrates',\n",
        " u'deverell',\n",
        " u'disabuse',\n",
        " u'disabuse',\n",
        " u'disabused',\n",
        " u'disagree',\n",
        " u'disagreed',\n",
        " u'disagrees',\n",
        " u'disapproves',\n",
        " u'disbelieve',\n",
        " u'disconnect',\n",
        " u'disconnects',\n",
        " u'discontent',\n",
        " u'disembark',\n",
        " u'disengage',\n",
        " u'disengaged',\n",
        " u'disharoon',\n",
        " u'disinfect',\n",
        " u'disinform',\n",
        " u'disinvite',\n",
        " u'dolezal',\n",
        " u'dominique',\n",
        " u'doralin',\n",
        " u'dorion',\n",
        " u'dunlavey',\n",
        " u'erion',\n",
        " u'esquibel',\n",
        " u'esquivel',\n",
        " u'fatheree',\n",
        " u'gabaldon',\n",
        " u'gabriele',\n",
        " u'geraldine',\n",
        " u'groseclose',\n",
        " u'hammontree',\n",
        " u'hardegree',\n",
        " u'hardigree',\n",
        " u'hargadon',\n",
        " u'hocevar',\n",
        " u'hohensee',\n",
        " u'honoree',\n",
        " u'honorees',\n",
        " u'huguenin',\n",
        " u'incomplete',\n",
        " u'incorrect',\n",
        " u'indigest',\n",
        " u'indigest',\n",
        " u'indirect',\n",
        " u'indiscreet',\n",
        " u'indistinct',\n",
        " u'inexact',\n",
        " u'inhumane',\n",
        " u'internee',\n",
        " u'internees',\n",
        " u'intertwine',\n",
        " u'intertwined',\n",
        " u'invitee',\n",
        " u'invitees',\n",
        " u'irelan',\n",
        " u'isabell',\n",
        " u'jeanpierre',\n",
        " u'joffrion',\n",
        " u'juliette',\n",
        " u'kathalene',\n",
        " u'kredietbank',\n",
        " u'lagardere',\n",
        " u'larosiere',\n",
        " u'lesperance',\n",
        " u'liliane',\n",
        " u'livermore',\n",
        " u'lopatin',\n",
        " u\"l'oreal\",\n",
        " u'lucianne',\n",
        " u'lunati',\n",
        " u'madelene',\n",
        " u'madelon',\n",
        " u'mallonee',\n",
        " u'mandarine',\n",
        " u'maneval',\n",
        " u'marcantel',\n",
        " u'marcial',\n",
        " u'marquerite',\n",
        " u'marroquin',\n",
        " u'martinique',\n",
        " u'maryann',\n",
        " u'maryanne',\n",
        " u'matalon',\n",
        " u'mcaleese',\n",
        " u'mcgarvey',\n",
        " u'mendivil',\n",
        " u'menjivar',\n",
        " u'meservey',\n",
        " u'mirabel',\n",
        " u'misapply',\n",
        " u'misconceive',\n",
        " u'misconceived',\n",
        " u'misconceives',\n",
        " u'misconstrue',\n",
        " u'misconstrues',\n",
        " u'misdirect',\n",
        " u'misinformed',\n",
        " u'misperceive',\n",
        " u'misperceived',\n",
        " u'misperceives',\n",
        " u'mispronounce',\n",
        " u'mispronounced',\n",
        " u'misreport',\n",
        " u'missildine',\n",
        " u'mitcheltree',\n",
        " u'mondragon',\n",
        " u'montavon',\n",
        " u'montiel',\n",
        " u'montserrat',\n",
        " u'nadal',\n",
        " u'natchitoches',\n",
        " u'noncompete',\n",
        " u'nondefense',\n",
        " u'ocain',\n",
        " u'ocheltree',\n",
        " u'orabel',\n",
        " u'ortegon',\n",
        " u'ourself',\n",
        " u'ourselves',\n",
        " u'overate',\n",
        " u'overhung',\n",
        " u'overtrain',\n",
        " u'patrolmen',\n",
        " u'pelletier',\n",
        " u'peloquin',\n",
        " u'perceval',\n",
        " u'persevere',\n",
        " u'perseveres',\n",
        " u'plamondon',\n",
        " u'poliquin',\n",
        " u'pospisil',\n",
        " u'propylene',\n",
        " u'puppeteer',\n",
        " u'puppeteers',\n",
        " u'quenneville',\n",
        " u'reacquire',\n",
        " u'reacquired',\n",
        " u'realign',\n",
        " u'realigned',\n",
        " u'reappraised',\n",
        " u'rearrest',\n",
        " u'reassess',\n",
        " u'reassessed',\n",
        " u'reassume',\n",
        " u'reassumed',\n",
        " u'reconnect',\n",
        " u'reconnects',\n",
        " u'reconvene',\n",
        " u'reconvened',\n",
        " u'reconvenes',\n",
        " u'recreate',\n",
        " u'recreates',\n",
        " u'redefine',\n",
        " u'redefined',\n",
        " u'redefines',\n",
        " u'redifer',\n",
        " u'redisplay',\n",
        " u'reelect',\n",
        " u'reemerge',\n",
        " u'reemerged',\n",
        " u'reenact',\n",
        " u'reenacts',\n",
        " u'reignite',\n",
        " u'reimpose',\n",
        " u'reimposed',\n",
        " u'reinspect',\n",
        " u'reinvent',\n",
        " u'reoccur',\n",
        " u'reoffend',\n",
        " u'restauranteur',\n",
        " u'restauranteurs',\n",
        " u'resupply',\n",
        " u'returnee',\n",
        " u'returnees',\n",
        " u'riopel',\n",
        " u'riunite',\n",
        " u'romanone',\n",
        " u'romanones',\n",
        " u'rosamund',\n",
        " u'saldivar',\n",
        " u'saldovar',\n",
        " u'salmeron',\n",
        " u'sanjuan',\n",
        " u'sanmiguel',\n",
        " u'sarazin',\n",
        " u'slushayete',\n",
        " u'soloman',\n",
        " u'sossamon',\n",
        " u\"submarine's\",\n",
        " u'submarines',\n",
        " u'terrebonne',\n",
        " u'thomasine',\n",
        " u'tienanmen',\n",
        " u'unbeknownst',\n",
        " u'undeclared',\n",
        " u'undercook',\n",
        " u'undercooked',\n",
        " u'underplay',\n",
        " u'underplayed',\n",
        " u'underrate',\n",
        " u'underseas',\n",
        " u'underserve',\n",
        " u'underserved',\n",
        " u'undersold',\n",
        " u'unemploy',\n",
        " u'uninvolved',\n",
        " u'unpreserved',\n",
        " u'unpreserved',\n",
        " u'unpreserved',\n",
        " u'unrehearsed',\n",
        " u'unreleased',\n",
        " u'unremarked',\n",
        " u'unresolved',\n",
        " u'unrevised',\n",
        " u'unsubscribe',\n",
        " u'unsubscribed',\n",
        " u'untoward',\n",
        " u'untoward',\n",
        " u'valdemar',\n",
        " u'valentin',\n",
        " u'verduin',\n",
        " u'versatile',\n",
        " u'villagran',\n",
        " u'villalon',\n",
        " u'villamil',\n",
        " u'villarreal',\n",
        " u'violin',\n",
        " u'violins',\n",
        " u'woodmansee',\n",
        " u'wotherspoon',\n",
        " u'zaldivar',\n",
        " u'zamarron',\n",
        " u'zavadil']"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('/Users/cem/Documents/csun/classes/math/582d/unit2-text/texts/pentametron.txt','r')\n",
      "pent = f.readlines()\n",
      "f.close()\n",
      "pent = [re.split(r'\\W+', i.strip().lower()) for i in pent]\n",
      "\n",
      "n = 30\n",
      "for i in range(n):\n",
      "  print ' '.join(pent[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "had sonic for the second time today\n",
        "commitment issues are in such a play \n",
        "i greet the devil with a smiley face\n",
        "a generation lost in cyber space\n",
        "i was already irritated too\n",
        "snow paxman was a funny interview\n",
        "i have a drinking problem on the low \n",
        "is justin even at the studio \n",
        "my cousin travis always looking out \n",
        " burritos self in bed and passes out \n",
        "now everybody telling me a lie\n",
        "luke is the cutest little fucker why\n",
        "i need a running buddy for the night \n",
        "i have evolved into a bagel bite\n",
        "i m tired\n",
        "la vida buena buena vida he\n",
        " i just a little died pattillo\n",
        "cute avi instant follow back \n",
        "i ve been in such a horrid mood today\n",
        "this is sarcastic anger by the way \n",
        "don t feed into unnecessary stress\n",
        "la vida buena\n",
        "if it requires pants the answers no\n",
        "she has a nice bikini body tho\n",
        "c mon c mon c mon c mon c mon\n",
        "don t panic\n",
        "who s going to become a hero then \n",
        "gave me a headache watching that again \n",
        "so england aren t doing very well\n",
        "i ve hit a follow limit what the hell\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[stress([ph for ph in pdict[i][0]]) for i in pent[0]]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "[[1], [1, 0], [1], [0], [1, 0], [1], [0, 1]]"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "HOMEWORK 4:\n",
      "Your homework for next Wednesday is to do a comparitive analysis of three texts of your choice. Texts can be anything from the NLTK corpora, or novels, poetry, Tweets etc. of your choice.\n",
      "\n",
      "I expect an IPython Notebook with at least four different comparisons, drawn from any of the methods described in these two notebooks. At least one of the comparisons must include figures such as the modal verbs chart or the sentence lengths chart.\n",
      "\n",
      "You should also start to think about possible Twitterbots. We will form your groups on Monday."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}